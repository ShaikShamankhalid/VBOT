

# ğŸ” VBOT â€“ RAG-Based Chat Application Using LLMs


## ğŸ“Œ Project Overview

**Goal**: Enable natural language querying over institutional data using a RAG-based AI chatbot.

**Models Used**: Meta LLaMA 3 (8B & 13B), FAISS for vector retrieval, BERT for embeddings, T5 for summarization.

**Interface**: Chat-based UI built with Chainlit for interactive document and query handling.

**Input**: Natural language queries + uploaded documents (e.g., academic PDFs, SQL data).

**Output**: Context-aware, factually grounded answers derived from structured and unstructured sources.

---

## ğŸ§ª Sample Input/Output

**Input**:  
Query â€“ *"Show all students who scored above 90 in Data Structures"*  
Platform â€“ VBOT Chat Interface  
AI Model â€“ Meta LLaMA 3 + FAISS  

**Output**:
```
[
  {"Name": "Ananya Sharma", "Roll No": "20CSE045", "Score": 94},
  {"Name": "Rajeev Nair", "Roll No": "20CSE078", "Score": 91},
  ...
]
Query Source: student_results.pdf
Retrieval Confidence: High
```

---

## ğŸ¤– Models Used

- **Meta LLaMA 3 (8B/13B)** â€“ For natural language response generation  
- **FAISS** â€“ For fast similarity search over vector embeddings  
- **BERT** â€“ Used for semantic embedding and document ranking  
- **T5** â€“ For summarization of long document responses  
- **DistilBERT** â€“ (Optional) lightweight transformer for quick inference  
- **Cross-Encoders / Re-rankers** â€“ For refining top-k retrieval accuracy

---

## ğŸ“ Dataset

**Documents & Sources**:
- Uploaded PDFs (student data, course files, transcripts)
- SQL Databases (structured institutional records)
- Sample Dataset File: `institutional_data.xlsx` *(not public)*

**Columns in Structured Data**:
- Student Name, Roll Number, Course Code, Faculty, Marks, Attendance, GPA, etc.

---

## ğŸš€ Features

- Natural language Q&A over your own documents and databases  
- Multi-turn chat with context retention  
- Document upload + SQL DB querying  
- PDF parsing, vectorization, semantic search  
- Role-based access control (RBAC)  
- Flexible prompt customization: Summarize / Explain / Opinion  

---

## ğŸ›  Installation

```bash
git clone https://github.com/ShaikShamanKhalid/VBOT.git
cd VBOT
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate for Windows
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

- `params.yaml`: Set vector dimensions, DB connection, model paths, etc.  
- `schema.yaml`: Define table structures and metadata formats  

---

## ğŸ’¡ How to Use

```bash
python app.py
```

1. Upload your document (PDF or CSV)
2. Type your query in natural language
3. View precise, explainable AI responses  
4. Follow up with multi-turn queries

---

## ğŸ“‚ Project Structure

```
VBOT/
â”œâ”€â”€ app.py                 # Entry point
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ params.yaml            # Configs
â”œâ”€â”€ schema.yaml            # Database schema
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingestion/    # Data ingestion logic
â”‚   â”œâ”€â”€ preprocessing/     # Clean, chunk, embed text
â”‚   â”œâ”€â”€ models/            # Retrieval + generation modules
â”‚   â””â”€â”€ utils/             # Common functions
â”œâ”€â”€ artifacts/             # Vector DBs, Logs, Saved Models
â”œâ”€â”€ public/                # UI static assets
â””â”€â”€ test.ipynb             # Sample test notebook
```

---

## ğŸ§  Key Technologies

- **Hugging Face Transformers**
- **LangChain**
- **FAISS**
- **Chainlit UI**
- **PyMuPDF**
- **GraphDB / Neo4j**
- **SQLAlchemy** for database integration

---

## ğŸ¤ Contributing

1. Fork this repository  
2. Create a new branch: `git checkout -b your-feature-name`  
3. Commit your changes  
4. Push to your fork  
5. Open a pull request ğŸš€



## ğŸ“¬ Contact

For feedback, bugs, or feature requests, please open an issue in the [GitHub Issues](https://github.com/ShaikShamanKhalid/VBOT/issues) section.

---

Let me know if you'd like this exported as a downloadable `README.md` file or further tailored to match GitHub README aesthetics!
